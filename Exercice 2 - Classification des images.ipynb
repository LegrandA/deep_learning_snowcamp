{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification des images : Lasagnes vs. Hot-Dog (vs. Hamburgers vs. Raviolis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons nous intéresser à la reconnaissance d'images, en bon anglais : **Computer Vision**\n",
    "\n",
    "Nous aborderons les éléments suivants : \n",
    "* Les réseaux de convolutions (a.k.a. convnets a.k.a. CNN)\n",
    "* L'augmentation des données \n",
    "* La réutilisation et l'adaptation de réseaux existants\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le MNIST (le Hello World de la classification d'images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le MNIST (Mixed National Institute of Standards and Technology) est une base de données contenant 70 000 (60 000 pour l'entrainement et 10 000 pour la validation) chiffres écrits à la main. Avec ce jeu de données, nous pouvons construire des algorithmes permettant de reconnaitre les chiffres.\n",
    "\n",
    "Un réseau de neurones traditionnel (totalement connecté), comme pour le précédent exercice de classification du vin, fonctionnera dans une certaine mesure. Cependant, les performances (qualité du modèle évaluée avec la précision des résultats) seront bien meilleures avec un réseau de convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU or not GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre réseau prendra en paramètres des images de chiffres écrits manuellement, ces images ayant pour dimension 28 pixels sur 28, et un seul canal colorimétrique (une image en niveau de gris pour le reformuler clairement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du modèle et ajout des 3 premières couches (Convolution) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout des couches totalement connectées (Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "\"\"\"\n",
    "    Ajout d'une couche dense (64 neurones) avec une activation relu\n",
    "\"\"\"\n",
    "model.add(...)\n",
    "\"\"\"\n",
    "    Ajout d'une couche dense (10 neurones car 10 catégories) avec une activation (à choisir ;) )\n",
    "\"\"\"\n",
    "model.add(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichages des 9 premières images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(train_images[i], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Class {}\".format(train_labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation et redimensionnement des données d'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de procéder à l'entrainement, nous redimensionnons les données pour qu'elles soient compatibles avec le format d'entrée de notre réseau (qui contient 4 dimensions).\n",
    "\n",
    "Before training, we’ll preprocess the data by reshaping it into the shape the network\n",
    "expects and scaling it so that all values are in the [0, 1] interval. Previously, our train-\n",
    "ing images, for instance, were stored in an array of shape (60000, 28, 28) of type\n",
    "uint8 with values in the [0, 255] interval. We transform it into a float32 array of\n",
    "shape (60000, 28 * 28) with values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Nous ajoutons 1 dimension pour 1 canal (le canal des niveaux de gris)\n",
    "\"\"\"\n",
    "train_images = train_images.reshape( (60000, ... , ... , ...) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Nous divisons ensuite les valeurs de \"pixels\" de l'images pour qu'elles soient comprises entre 0 et 1. (au lieu de 0 à 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Nous effectuons la même manipulation pour les données de test\n",
    "\"\"\"\n",
    "test_images = test_images.reshape((10000, ... , ... , ...))\n",
    "test_images = test_images.astype('float32') / ...\n",
    "\n",
    "\"\"\"\n",
    "    Nous transformons les données cibles en catégories grâce à la fonction to_categorical fournie par keras \n",
    "\"\"\"\n",
    "train_labels = ...\n",
    "test_labels = ...\n",
    "\n",
    "\"\"\"\n",
    "    Nous pouvons  compiler le modèle\n",
    "\"\"\"\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss=...,\n",
    "    metrics=[...])\n",
    "\n",
    "\"\"\"\n",
    "    Nous procédons enfin à l'entrainement du modèle, avec 5 epochs et des batchs de taille 64\n",
    "\"\"\"\n",
    "\n",
    "model.fit(..., ..., ..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasagnes vs Hots-Dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier des chiffres manuscrits est un passage obligé lorsque l'on débute dans la classification d'images. Mais ce type d'architecture peut être utilisé pour classifiers tout type d'images.\n",
    "\n",
    "Ici, nous allons classifier des photos de plats, issus du dataset food101 ( https://www.vision.ee.ethz.ch/datasets_extra/food-101/ )\n",
    "\n",
    "Dans ce dataset nous avons 100 catégories de plats. Chaque catégorie contenant 1000 images.\n",
    "1000 images c'est à la fois beaucoup (il a fallu récupérer ces photographies, les classifier manuellement, etc.) mais c'est très peu pour un algorithme de reconnaissance d'images qui a besoin de beaucoup plus d'images.\n",
    "\n",
    "Cette exercice reprend l'article du blog Keras 'Cats vs. Dogs' (https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html). L'article d'origine permet de classifier entre 2 catégories (classification binaire). Notre objectif lors de cet atelier est de classifier parmi 4 catégories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réutilisation d'un réseau existant\n",
    "\n",
    "Nous pourrions créer notre propre réseau de convolution et l'entrainer avec les 100 000 images du dataset pour calculer les différents paramètres du modèle. Malheureusement, cela serait un peu long (vous pouvez essayer chez vous...).\n",
    "\n",
    "Une autre approche serait de se baser sur un réseau existant. Keras propose différents réseaux pré-entrainés et prêt à l'emploi ( https://keras.io/applications/ ): \n",
    "\n",
    "* VGG16\n",
    "* VGG19\n",
    "* ResNet50\n",
    "* Inception V3\n",
    "* Xception\n",
    "* ..\n",
    "\n",
    "Ces réseaux ont été entrainés sur le dataset ImageNet : 1.4 millions d'images classifiées en 1000 catégories. Outre le fait que ces réseaux fonctionnent déjà très bien pour la reconnaissance d'images, le fait de les avoir entrainés sur un tel volume d'images leur a permis de comprendre de quoi était composé une image : formes, contours, plans, etc.\n",
    "\n",
    "Lorsque nous réutilisons (en les adaptant) ces réseaux pré-entrainés, nous bénéficions de cette connaissance ce qui induit un gain de temps non-négligeable.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(photo):\n",
    "    \"\"\"\n",
    "        Analyse l'image et recherche les catégories auxquelles elle appartient\n",
    "    \"\"\"\n",
    "    img = image.load_img(photo, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = model.predict(x)\n",
    "    preds = decode_predictions(features)\n",
    "    return preds\n",
    "\n",
    "def display_photo(photo):\n",
    "    display(Image(filename=photo))\n",
    "    \n",
    "def display_and_predict(photo):\n",
    "    display_photo(photo)\n",
    "    print(\"Predictions = \" + str(predict(photo)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une lasagne..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_and_predict('./snowcamp/datasets/images/train/lasagna/1089702.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_and_predict('snowcamp/datasets/images/train/lasagna/2009224.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_and_predict('snowcamp/datasets/images/train/hot_dog/1000288.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_and_predict('snowcamp/datasets/images/train/hot_dog/302949.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = 'snowcamp/datasets/images/train/'\n",
    "validation_data_dir = 'snowcamp/datasets/images/validation/'\n",
    "\"\"\"\n",
    "    Les largeurs et hauteurs d'images devraient être 224\n",
    "\"\"\"\n",
    "img_width, img_height = ... , ...\n",
    "\n",
    "\"\"\"\n",
    "    Nombre de catégories (2 mini). Il faudra adapter les contenus de <train_data_dir> et <validation_data_dir> en fonction\n",
    "\"\"\"\n",
    "nb_categories = 2\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "\"\"\"\n",
    "    800 images / catégorie pour l'entrainement\n",
    "\"\"\"\n",
    "nb_train_samples = nb_categories * 800\n",
    "\n",
    "\"\"\"\n",
    "    200 images / catégorie pour la validation\n",
    "\"\"\"\n",
    "nb_validation_samples = nb_categories * 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "\n",
    "Avec peu d'images, il est peu probable qu'un réseau de convolution généralise correctement. Il ne saura pas catégoriser de nouvelles images (jamais vues) alors qu'il sera très bon sur les images utilisées lors de l'entrainement (Overfitting).\n",
    "\n",
    "Pour éviter ce phénomène, nous allons générer de nouvelles images issues de celles en notre possession et auxquelles nous  avons appliquer un certain nombre de transformations aléatoires. \n",
    "\n",
    "La classe ImageDataGenerator permet d'effectuer tout cela avec Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just a few of the options available (for more, see the Keras documentation).\n",
    "Let’s quickly go over this code:\n",
    "* rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures.\n",
    "* width_shift and height_shift are ranges (as a fraction of total width or\n",
    "height) within which to randomly translate pictures vertically or horizontally.\n",
    "* shear_range is for randomly applying shearing transformations.\n",
    "* zoom_range is for randomly zooming inside pictures.\n",
    "* horizontal_flip is for randomly flipping half the images horizontally—rele-\n",
    "vant when there are no assumptions of horizontal asymmetry (for example,\n",
    "real-world pictures).\n",
    "* fill_mode is the strategy used for filling in newly created pixels, which can\n",
    "appear after a rotation or a width/height shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Initalisez le  ImageDataGenerator en positionnant les attributs:\n",
    "    *  rotation_range\n",
    "    *  width_shift_range\n",
    "    * height_shift_range\n",
    "    * shear_range\n",
    "    * zoom_range\n",
    "\"\"\"\n",
    "datagen = ImageDataGenerator(\n",
    "    ...,\n",
    "    ...,\n",
    "    ...,\n",
    "    ...,\n",
    "    ...,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Sélection d'une image sur laquelle nous allons appliquer nos transformations aléatoires\n",
    "\"\"\"\n",
    "import os \n",
    "\n",
    "from keras.preprocessing import image\n",
    "fnames = [os.path.join(train_data_dir + 'lasagna/', fname) for\n",
    "fname in os.listdir(train_data_dir + 'lasagna/')]\n",
    "img_path = fnames[3]\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Visualisation des transformations\n",
    "\"\"\"\n",
    "x = image.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_bottleneck_features():\n",
    "\n",
    "    \"\"\"\n",
    "        Nous allons donc générer de nouvelles images, et passer chacune de ces images dans les couches de convolution (\n",
    "        en enlevant le classifier)\n",
    "        Nous stockons ensuite les matrices résultantes dans des fichiers (nommés bottleneck_*) que nous réutiliserons par la suite.\n",
    "    \"\"\"\n",
    "    datagen = ...\n",
    "\n",
    "    \"\"\"\n",
    "        Chargement du modèle (en ignorant le classifier)\n",
    "    \"\"\"\n",
    "    model = VGG16(include_top=... , weights='imagenet')\n",
    "\n",
    "    print (\"Create train matrix...\")\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n",
    "    \n",
    "    print (\"Bottleneck features are OK...\")\n",
    "    np.save(open('bottleneck_features_train_all_v2.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "    print (\"Create validation matrix...\")\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    \n",
    "    np.save(open('bottleneck_features_validation_all_v2.npy', 'wb'),\n",
    "            bottleneck_features_validation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\"\"\"\n",
    "    Nombre d'epochs (50 pour commencer)\n",
    "\"\"\"\n",
    "epochs = ...\n",
    "top_model_weights_path='bottleneck_fc_model_all_v2.h5'\n",
    "\n",
    "#Create labels\n",
    "def create_target_row(nb_categories, cat):\n",
    "    res = [0] * nb_categories\n",
    "    res[cat] = 1\n",
    "    return res\n",
    "\n",
    "def create_target(rows_by_cat, nb_cat):\n",
    "    target = []\n",
    "    for i in range(0,nb_cat):\n",
    "        for j in range(0, rows_by_cat):\n",
    "            target.append(create_target_row(nb_cat, i))\n",
    "    return np.array(target)\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train_all_v2.npy', 'rb'))\n",
    "    # the features were saved in order, so recreating the labels is easy\n",
    "    \"\"\"\n",
    "        On crée autant de lignes que d'images 'train'\n",
    "    \"\"\"\n",
    "    train_labels = create_target( ... , nb_categories)\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation_all_v2.npy', 'rb'))\n",
    "    \n",
    "    \"\"\"\n",
    "        On crée autant de lignes que d'images 'test'\n",
    "    \"\"\"\n",
    "    validation_labels = create_target( ... , nb_categories)\n",
    "\n",
    "    \"\"\"\n",
    "        Ajout du classifier\n",
    "        La première couche dense aura 256 neurones et une activation relu\n",
    "        Le dropout aura pour valeur entre 0 et 0.5 (voire plus pour les joueurs ;) )\n",
    "        Et enfin la dernière couche servira à déterminer la classe résultante\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(... , activation= ...))\n",
    "    model.add(Dropout(... ))\n",
    "    model.add(Dense(..., activation = ...))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    \n",
    "    model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\"\"\"\n",
    "    On ouvre la matrice des bottleneck features (train)\n",
    "\"\"\"\n",
    "train_data = np.load(open('bottleneck_features_train_all_v2.npy', 'rb'))\n",
    "\n",
    "input_tensor = Input( shape=(img_width,img_height ,3) )\n",
    "base_model = VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
    "\n",
    "\"\"\"\n",
    "    On redéfinit le classifier\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(..., activation=...))\n",
    "top_model.add(Dropout(...))\n",
    "top_model.add(Dense(..., activation= ...))\n",
    "\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "\"\"\"\n",
    "    On charge le modèle\n",
    "\"\"\"\n",
    "\n",
    "loaded_model = Model(inputs= base_model.input, outputs= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    On effectue quelques prédictions !\n",
    "\"\"\"\n",
    "\n",
    "img = image.load_img('./snowcamp/datasets/images/validation/lasagna/3355991.jpg', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "features = loaded_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = image.load_img('./snowcamp/datasets/images/validation/hot_dog/2889560.jpg', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "features = loaded_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
